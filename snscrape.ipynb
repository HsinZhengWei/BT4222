{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65793cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad48175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:26: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "<timed exec>:26: DeprecatedFeatureWarning: username is deprecated, use user.username instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01: 309 total tweets retrieved\n",
      "2019-01-02: 500 total tweets retrieved\n",
      "2019-01-03: 500 total tweets retrieved\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Specify the search criteria\n",
    "keyword = 'aapl'\n",
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2019, 1, 3)\n",
    "\n",
    "# Create a list of dates between start_date and end_date\n",
    "delta = timedelta(days=1)\n",
    "date_range = pd.date_range(start_date, end_date, freq='D').tolist()\n",
    "\n",
    "# Create an empty list to store the tweets\n",
    "tweets = []\n",
    "#limit of tweets per day\n",
    "limit = 500\n",
    "\n",
    "# Loop over each day in the date range and retrieve X tweets per day\n",
    "#if count == limit or when the loop ends\n",
    "for i in range(len(date_range)):\n",
    "    day = date_range[i].strftime('%Y-%m-%d')\n",
    "    dayNext = (date_range[i] + timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "    query = f'{keyword} since:{day} until:{dayNext} lang:en'\n",
    "    count = 0\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "        if (count == limit):\n",
    "            break\n",
    "        tweets.append([tweet.date, tweet.content, tweet.username, tweet.likeCount])\n",
    "        count+= 1\n",
    "    print(f'{day}: {count} total tweets retrieved')\n",
    "\n",
    "# Convert the list of tweets to a Pandas DataFrame\n",
    "df = pd.DataFrame(tweets, columns=['Datetime', 'Text', 'Username', 'likeCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4aa8905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>likeCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 23:55:28+00:00</td>\n",
       "      <td>$AAPL #patent #maintenance event EXP - Patent ...</td>\n",
       "      <td>treabase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 23:50:06+00:00</td>\n",
       "      <td>Early to mid January performer : gs ， aapl  co...</td>\n",
       "      <td>qingxia_NXP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 23:47:43+00:00</td>\n",
       "      <td>Join @RobinhoodApp and we'll both get a stock ...</td>\n",
       "      <td>wetthamjoe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 23:40:28+00:00</td>\n",
       "      <td>$AAPL #patent #maintenance event EXP - Patent ...</td>\n",
       "      <td>treabase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 23:37:55+00:00</td>\n",
       "      <td>@MohnishPabrai @rickbroma I bet the shrimp at ...</td>\n",
       "      <td>88888sAccount</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>2019-01-03 21:22:28+00:00</td>\n",
       "      <td>@daesr1 @NotaBubble @VendbienJon @7wtc @marc_s...</td>\n",
       "      <td>FilmProfessor9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>2019-01-03 21:22:13+00:00</td>\n",
       "      <td>$AAPL chart of history. Their cash flow can bu...</td>\n",
       "      <td>LinYingjun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>2019-01-03 21:22:06+00:00</td>\n",
       "      <td>$AAPL Apple suffers its biggest single-day los...</td>\n",
       "      <td>Options</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>2019-01-03 21:22:04+00:00</td>\n",
       "      <td>Stock Market Update: Stocks Fall on Apple Warn...</td>\n",
       "      <td>FinanzLinksCom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>2019-01-03 21:21:05+00:00</td>\n",
       "      <td>Thanks to @realDonaldTrump's stupid fight with...</td>\n",
       "      <td>thbthttt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "0    2019-01-01 23:55:28+00:00   \n",
       "1    2019-01-01 23:50:06+00:00   \n",
       "2    2019-01-01 23:47:43+00:00   \n",
       "3    2019-01-01 23:40:28+00:00   \n",
       "4    2019-01-01 23:37:55+00:00   \n",
       "...                        ...   \n",
       "1304 2019-01-03 21:22:28+00:00   \n",
       "1305 2019-01-03 21:22:13+00:00   \n",
       "1306 2019-01-03 21:22:06+00:00   \n",
       "1307 2019-01-03 21:22:04+00:00   \n",
       "1308 2019-01-03 21:21:05+00:00   \n",
       "\n",
       "                                                   Text        Username  \\\n",
       "0     $AAPL #patent #maintenance event EXP - Patent ...        treabase   \n",
       "1     Early to mid January performer : gs ， aapl  co...     qingxia_NXP   \n",
       "2     Join @RobinhoodApp and we'll both get a stock ...      wetthamjoe   \n",
       "3     $AAPL #patent #maintenance event EXP - Patent ...        treabase   \n",
       "4     @MohnishPabrai @rickbroma I bet the shrimp at ...   88888sAccount   \n",
       "...                                                 ...             ...   \n",
       "1304  @daesr1 @NotaBubble @VendbienJon @7wtc @marc_s...  FilmProfessor9   \n",
       "1305  $AAPL chart of history. Their cash flow can bu...      LinYingjun   \n",
       "1306  $AAPL Apple suffers its biggest single-day los...         Options   \n",
       "1307  Stock Market Update: Stocks Fall on Apple Warn...  FinanzLinksCom   \n",
       "1308  Thanks to @realDonaldTrump's stupid fight with...        thbthttt   \n",
       "\n",
       "      likeCount  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1304          2  \n",
       "1305          1  \n",
       "1306          0  \n",
       "1307          0  \n",
       "1308          0  \n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d08d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2019-01-01 19:25:18+00:00</td>\n",
       "      <td>2. AirPods will continue their dominance as th...</td>\n",
       "      <td>jmj</td>\n",
       "      <td>490</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-01-01 22:03:44+00:00</td>\n",
       "      <td>New way of living for 2019.\\n\\nBuy things I wa...</td>\n",
       "      <td>ACXtrades</td>\n",
       "      <td>112</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2019-01-01 01:35:46+00:00</td>\n",
       "      <td>Have a happy new year people may the $SPY $QQQ...</td>\n",
       "      <td>Sandro_power</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2019-01-01 13:19:28+00:00</td>\n",
       "      <td>$AAPL monthly testing support and moving on ex...</td>\n",
       "      <td>johnscharts</td>\n",
       "      <td>28</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-01-01 19:58:07+00:00</td>\n",
       "      <td>$SPX 2018 contributors: total return was -4.38...</td>\n",
       "      <td>hsilverb</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2019-01-03 22:08:08+00:00</td>\n",
       "      <td>#JRMHatTrick a nice day in Futures, FX, and Op...</td>\n",
       "      <td>TheJasonJenkins</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>2019-01-03 22:04:28+00:00</td>\n",
       "      <td>@askslim saw analyst on bloomberg still applyi...</td>\n",
       "      <td>jarzt</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>2019-01-03 21:53:16+00:00</td>\n",
       "      <td>Stock Market Heat Map Today\\n\\n$AAPL $MSFT $GO...</td>\n",
       "      <td>ShortSqueezed1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2019-01-03 21:51:47+00:00</td>\n",
       "      <td>@kerberos007 this is just the first day of the...</td>\n",
       "      <td>ladytrader33</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>2019-01-03 21:49:19+00:00</td>\n",
       "      <td>@lhamtil I would love to see dip below $95 (no...</td>\n",
       "      <td>BeboSnipez</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "81   2019-01-01 19:25:18+00:00   \n",
       "34   2019-01-01 22:03:44+00:00   \n",
       "284  2019-01-01 01:35:46+00:00   \n",
       "185  2019-01-01 13:19:28+00:00   \n",
       "68   2019-01-01 19:58:07+00:00   \n",
       "...                        ...   \n",
       "1106 2019-01-03 22:08:08+00:00   \n",
       "1120 2019-01-03 22:04:28+00:00   \n",
       "1163 2019-01-03 21:53:16+00:00   \n",
       "1170 2019-01-03 21:51:47+00:00   \n",
       "1179 2019-01-03 21:49:19+00:00   \n",
       "\n",
       "                                                   Text         Username  \\\n",
       "81    2. AirPods will continue their dominance as th...              jmj   \n",
       "34    New way of living for 2019.\\n\\nBuy things I wa...        ACXtrades   \n",
       "284   Have a happy new year people may the $SPY $QQQ...     Sandro_power   \n",
       "185   $AAPL monthly testing support and moving on ex...      johnscharts   \n",
       "68    $SPX 2018 contributors: total return was -4.38...         hsilverb   \n",
       "...                                                 ...              ...   \n",
       "1106  #JRMHatTrick a nice day in Futures, FX, and Op...  TheJasonJenkins   \n",
       "1120  @askslim saw analyst on bloomberg still applyi...            jarzt   \n",
       "1163  Stock Market Heat Map Today\\n\\n$AAPL $MSFT $GO...   ShortSqueezed1   \n",
       "1170  @kerberos007 this is just the first day of the...     ladytrader33   \n",
       "1179  @lhamtil I would love to see dip below $95 (no...       BeboSnipez   \n",
       "\n",
       "      likeCount        Date  \n",
       "81          490  2019-01-01  \n",
       "34          112  2019-01-01  \n",
       "284          68  2019-01-01  \n",
       "185          28  2019-01-01  \n",
       "68           12  2019-01-01  \n",
       "...         ...         ...  \n",
       "1106          2  2019-01-03  \n",
       "1120          2  2019-01-03  \n",
       "1163          2  2019-01-03  \n",
       "1170          2  2019-01-03  \n",
       "1179          2  2019-01-03  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = df['Datetime'].dt.date\n",
    "filteredDf = df.sort_values(by = ['Date', 'likeCount'], ascending = [True, False]).groupby('Date').head(100)\n",
    "filteredDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name\n",
    "fileName = 'Jan2019.csv'\n",
    "filteredDf.to_csv(fileName, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bf931",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "limit = 100\n",
    "\n",
    "keyword = 'apple OR appl'\n",
    "since_date = '2018-1-1'\n",
    "until_date = '2018-1-1'\n",
    "\n",
    "query = f'{keyword} since:{since_date} until:{until_date} lang:en'\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    if len(tweets) % 100 == 0:\n",
    "        print(len(tweets))\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "    else:\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from user\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "query = \"(from:elonmusk) until:2020-01-01 since:2010-01-01\"\n",
    "tweets = []\n",
    "limit = 5000\n",
    "\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "    # print(vars(tweet))\n",
    "    # break\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "        \n",
    "df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
    "print(df)\n",
    "\n",
    "# to save to csv\n",
    "# df.to_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596dfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Specify the search criteria\n",
    "keyword = 'aapl'\n",
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2019, 1, 5)\n",
    "\n",
    "# Create a list of dates between start_date and end_date\n",
    "delta = timedelta(days=1)\n",
    "date_range = pd.date_range(start_date, end_date, freq='D').tolist()\n",
    "\n",
    "# Create an empty list to store the tweets\n",
    "tweets = []\n",
    "#limit of tweets per day\n",
    "limit = 500\n",
    "\n",
    "# Loop over each day in the date range and retrieve X tweets per day\n",
    "#if count == limit or when the loop ends\n",
    "for i in range(len(date_range)):\n",
    "    day = date_range[i].strftime('%Y-%m-%d')\n",
    "    dayNext = (date_range[i] + timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "    query = f'{keyword} since:{day} until:{dayNext} lang:en'\n",
    "    count = 0\n",
    "    day_tweets = []\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "#         once count hits limit, sort the current list of x tweets and take the top 100 basd on likeCount\n",
    "        if (count == limit):\n",
    "            sorted_tweets = sorted(day_tweets, key=lambda x: x[3], reverse=True)\n",
    "            top_tweets = sorted_tweets[:100]\n",
    "            tweets += top_tweets\n",
    "            break\n",
    "        day_tweets.append([tweet.date, tweet.content, tweet.username, tweet.likeCount])\n",
    "        count+= 1\n",
    "    print(f'{day}: {count} total tweets retrieved')\n",
    "\n",
    "# Convert the list of tweets to a Pandas DataFrame\n",
    "df = pd.DataFrame(tweets, columns=['Datetime', 'Text', 'Username', 'likeCount'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
